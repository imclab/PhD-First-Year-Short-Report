\chapter{Research Plan}
	
	\label{sec:research-plan}
	
	In this chapter an outline of the work to be carried out is presented. Due to
	the early stage of the research, planned later work is presented with less
	detail.  Figure \ref{fig:plan-gantt} shows a Gantt chart identifying the key
	stages of the project which are outlined in chronological order in the
	sections below.
	
	\begin{figure}[b!]
		\center
		\input{figures/plan-gantt}
		
		\caption[Research plan Gantt chart.]{Gantt chart of proposed research plan.
		Arrows indicate dependencies, thick lines indicate slack.  Note non-linear
		scale.}
		\label{fig:plan-gantt}
	\end{figure}
	
	
	\section{SpiNNaker Modelling}
		
		% In order to experiment with the way new interconnection options affect
		% SpiNNaker an accurate model is required. Will work with Mikel and Javier to
		% extend the SpiNNaker simulator used in the original paper to include models
		% of inter-board links.
		%
		% How long will this take?
		
		As part of the ongoing SpiNNaker project a study is being carried out to
		compare how network simulations compare with the real hardware. As part of
		this work, researchers have built an FPGA-accelerated model of SpiNNaker's
		interconnection network. The work hopes to verify the accuracy of the model
		against both a traditional software model and the final silicon
		implementation. The results of this work are intended for a journal
		publication aiming for submission around the end of September 2013.
		
		My participation in this project will be to develop the software simulation
		to model and evaluate the network implemented in SpiNNaker. Once built, this
		simulator will be valuable for my own research into alternative network
		topologies.  This section outlines in further detail the motivation and
		requirements for the simulator followed by a discussion of its applications
		for my own work.
		
		\subsection{Software Simulator Limitations}
		
			A prototype software model has been built using the INSEE simulator
			\cite{navaridas11insee} which is designed to simulate a wide variety of
			networks. Unfortunately, INSEE's router model is different from that found
			in SpiNNaker and the FPGA model. The differences in their behaviour are
			outlined below.
			
			% TODO: elaborate
			
			One of the major limitations of INSEE is that it is only able to model
			point-to-point traffic and will require extending to support multicast
			traffic which is at the heart of SpiNNaker's anticipated usage for neural
			network simulation. However, since this limitation is also shared by the
			FPGA implementation, only point-to-point traffic is considered by this
			work in all three systems.
			
			The other key difference between INSEE and the SpiNNaker architecture is
			the way packets from incoming links are arbitrated. Figure
			\ref{fig:arbitration} shows the arbitration schemes for INSEE and
			SpiNNaker. INSEE uses a simple round-robin arbitration scheme while
			SpiNNaker (and the FPGA model) use a tree of arbiters\footnote{The
			bandwidth available at each level of the arbitration tree scales with the
			maximum input bandwidth for each level.}.
			
			\begin{figure}
				\begin{subfigure}[t]{0.50\textwidth}
					\center
					\input{figures/arbitrationINSEE}
					
					\caption{INSEE}
					\label{fig:arbitrationINSEE}
				\end{subfigure}
				\begin{subfigure}[t]{0.50\textwidth}
					\center
					\input{figures/arbitrationSpiNNaker}
					
					\caption{SpiNNaker}
					\label{fig:arbitrationSpiNNaker}
				\end{subfigure}
				
				\caption[Incoming packet arbitration schemes in INSEE and
				SpiNNaker.]{Incoming packet arbitration schemes in INSEE and SpiNNaker.
				Boxes marked `RR' are round-robin arbiters, P1-P18 are connections to
				local processor cores.}
				\label{fig:arbitration}
			\end{figure}
			
			The differences caused by this extend beyond the order in which contesting
			requests will be serviced. In INSEE, each input has a buffer associated
			with it from which the router will extract messages and forward them to
			the input buffer of the next node, one per simulated cycle. In the
			SpiNNaker design, messages are buffered at each level of the tree and
			eventually placed in a pipeline within the router (equivalent to further
			buffering) and an output buffer. The interaction of these buffers is not
			modelled by INSEE and thus the results produced will be less well matched
			with the actual SpiNNaker system.
			
			% Part of the aim of the work is to produce a comparison between this
			% software model, an FPGA model and a prototype system. Successful
			% comparison of the three will allow higher certainty in results obtained
			% from other work (namely the interconnect experiments to follow).
		
		\subsection{Simulator Improvement Plan}
			
			\label{sec:simulator-improvement-plan}
			
			Given the limitations of INSEE mentioned in the previous section, two
			possible approaches must be considered. Either INSEE must be modified to
			incorporate a more realistic model of the router or an alternative
			simulator must be used.  One important factor in the decision is the
			`ramp-up' time required to gain familiarity with the INSEE code-base
			compared with the time required to develop or extend an alternative
			simulator. The other factor is the utility of the simulator for my own
			research.
			
			Since INSEE is an established tool which has been used in similar work it
			is potentially a strong choice. To determine its suitability for this work
			and my own research a small time will be initially spent analysing its
			design. If it is found to be suitable development of an extended version
			will commence.
			
			A possible alternative to INSEE is the simulator developed during the
			preliminary interconnect study in \S\ref{sec:interconnect-modelling}.
			Like INSEE, it has already been used to simulate the SpiNNaker
			Interconnect and so configurations exist for SpiNNaker like machines.
			Because of the author's familiarity with the tool, extending the router
			model should be straight-forward.
	
	
	\section{Small-World Network Experiments}
		
		Given the availability of an extensible and proven simulator, the next stage
		of my research will be to use it to model the behaviour of small-world style
		networks with more realistic traffic and wiring constraints.
		
		The work done in \S\ref{sec:small-world-super-computers} measured average
		shortest-path length in the networks examined. This measure corresponds to
		the average path length for uniform-random traffic in a real network with
		the same topology. In brain simulation systems such as SpiNNaker, much of
		the traffic is expected to be local and so uniform-random traffic is not
		representative.  This work will test the performance of small-world networks
		with more realistic traffic.
		
		The other shortcoming found during the preliminary study was that when
		physical wiring was restricted in length (as in real systems), the logical
		distance covered by links in different parts of the system becomes uneven.
		Since the folding and rack/cabinet placement which takes place in real
		machines such as SpiNNaker is much more intricate than the simple ring
		studied, these effects may become insignificant making wire-length limiting
		schemes profitable.
		
		This work is intended to take around one further month including ample time
		for writing up and further experimentation with wiring schemes if required.
	
	
	\section{Topology Comparison}
		
		% Look at a whole load of popular topologies and possibly look at having
		% two/more networks.
		
		With the small-world network testing complete, the simulator should now be
		mature enough to begin further experiments with alternative, potentially
		more structured topologies. This will be done to empirically test
		alternative topologies for use in SNN simulation.
		
		This work will follow on from the experiments carried out by Vainbrand and
		Ginosar which was limited to widely used, more generic network topologies
		with alternatives which may be better suited to the problem
		\cite{vainbrand11}. For example, topologies such as express cubes
		\cite{dally91} offer improved performance for a limited amount of non-local
		traffic while preserving the local performance of mesh and torus networks.
	
	\section{Placement and Routing}
		
		Given the scale of the SpiNNaker machine and the networks it simulates, the
		NP-complete task of allocating processing tasks in each node in the system
		(placement) and routing messages between them (routing) is an important
		consideration. Current architectures, such as SpiNNaker, use table based
		routing where a lookup table is used to decide where to route messages
		arriving at each node in the system. Such systems offer a lot of flexibility
		in the routing schemes that can be implemented but may also introduce
		constraints on the complexity of routes through the system when the routing
		tables are limited in size.
		
		The use of alternative topologies will require alternative routing schemes
		to be specified. In the above comparative work on possible topologies
		simple, na\"ive routing algorithms will be used. These simple to implement
		algorithms often result in non-optimal behaviour, especially with regard to
		load balancing \cite{dally04}. Given that systems such as SpiNNaker use
		packet-dropping flow control, where congested routes can cause packets to be
		dropped, the effects of load imbalance may cause localised areas of high
		packet losses which may significantly affect simulations
		\cite{greenfield10}.
		
		In this phase of work alternative routing algorithms which attempt to handle
		routing table depth and congestion control will be studied. The former
		problem is similar in style to the problem faced by chip and printed circuit
		design automation tools. The latter is largely covered by conventional
		interconnect/network routing algorithms. Combining and evaluating these two
		approaches will be where much of this time is spent.
	
	\section{Effects of Multicast}
		
		Following on from work on basic routing, the challenge of performing routing
		for multicast traffic must be considered. Multicast routing must route a
		message from a single source to multiple destinations, in the case of
		spiking neural networks, potentially thousands of destinations.
		
		Current approaches to multicast routing again are split between chip and
		circuit design and interconnect/network routing. Chip routers often
		constrain the paths in various ways, for example to ensure that latency to
		each destination is similar. This type of constraint is similar in style to
		those in SpiNNaker-like systems for example, the need to try and control
		branching to minimise routing table resource. Network routers, however, are
		often designed to reduce the bandwidth consumed by forking multipath routes
		as late as possible reducing the total number of links used. Once again,
		work must be done to combine and compare these two approaches.
	
	\section{Interconnect Technology Evaluation}
		
		% Can't use Silistix any more, HSS is nice but should we be using it
		% on-chip?
		
		Given a suitable topology, a further question is that of the actual
		implementation of the interconnect. Historically small-scale systems have
		used synchronous signals to communicate between various parts of the system.
		As systems have scaled, this is no longer feasible as clock distribution
		grows ever more difficult. Instead architectures have become prominent where
		individual, locally-synchronous components communicate via a
		locally-synchronous interconnect.
		
		Internally, the SpiNNaker chip uses an asynchronous NoC based on CHAIN
		\cite{plana07,bainbridge02} using IP from (the now defunct) Silistix Ltd.
		This interconnect is able to handle arbitration between the many incoming
		signals from on-board processors and external connections to other chips.
		Since this technology is no longer available, alternatives must be sought.
		
		SpiNNaker chips are interconnected using parallel, delay insensitive
		interconnects. These links, while adequate for the system's current scale,
		may not be trivially speeded up. More suitable external interconnects will
		likely be based on high speed serial as described in
		\S\ref{sec:high-speed-serial}.
		
		\section{`SpiNNaker 2' Architecture}
		
		% It is likely that a new version of SpiNNaker will be designed with some
		% funding coming in soon. Based on the research into the interconnect here,
		% would an alternative topology be appropriate?
		
		Based on the preceding work and on further developments within the
		SpiNNaker project, a new architecture for neural network simulation will be
		proposed. In particular the architecture is intended to be a successor to
		the SpiNNaker platform aimed at a similar communication-bound model.
		
		\subsection{Scaling}
			
			Due to the advance of Moore's law, several times more logical capacity
			will be available for this next generation architecture compared to the
			previous revision. It is assumed that it will be possible to fit a larger
			number of cores into a single chip along with larger memories both for the
			on-board processors and routers.
			
			The preceding work will be used to decide on the type of topology and
			routing systems to be used. It is expected that access to larger routing
			table resource as well as more area for routing logic will be available.
		
		\subsection{Interconnection Network}
			
			One of the known limitations of SpiNNaker's interconnection network is
			that it has been optimised largely for the style of traffic required while
			simulations are in progress, in particular it deals very well with small,
			multicast packets whose delivery does not need to be guaranteed, as with
			biological spikes.
			
			Other important tasks, however, are not handled as well such as
			initialisation and result collection. These tasks require reliable
			communication, typically with a relatively larger data payload. This is
			currently facilitated by the SpiNNaker Datagram Protocol (SDP)
			\cite{temple11} which allows non-guaranteed point-to-point transmission of
			up to 64 kilobytes of data. Though this offers the ability to load
			configurations to SpiNNaker chips, collecting data becomes more difficult.
			With larger, multi-board systems currently in testing, contention for the
			links surrounding a central node during data collection become saturated
			resulting in a large number of packets being dropped.
		
		\subsection{Link Technology}
			
			% Switching away from Silistix (they went bye-bye!), alternative
			% technologies, e.g. high-speed serial, might be used to link chips
			% together. Such technologies may have very different cost structures and
			% call for new network topologies. Given we currently have concentrated
			% multiplexed links, why not have the same for stuff lower down?
			
			The underlying Silistix technology used by SpiNNaker's links is not
			available for new systems and must be replaced. Based on research into
			link technologies a decision must be made for the new system. This choice
			will strongly influence the design of the network.
		
		
		\subsection{Evaluation}
			
			The proposed topology will be evaluated by simulation building on the
			simulators developed earlier in the project. It is hoped that more
			information about the actual usage and traffic patterns encountered by the
			current SpiNNaker hardware will be available to drive this simulation and
			to present a point of comparison.
		
